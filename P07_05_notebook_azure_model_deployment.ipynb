{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Déploiement du modèle sur Azure Machine Learning\n",
        "\n",
        "(Ce notebook est à utiliser sur Azure Machine Learning)\n",
        "\n",
        "On va déployer le modèle entraîné et sauvegardé comme un web service sur Azure Container Instances (ACI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Récupération du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1655138940374
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registering model bidirectional_lstm\n"
          ]
        }
      ],
      "source": [
        "# Récupérer le modèle entraîné\n",
        "from azureml.core import Workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "from azureml.core.model import Model\n",
        "\n",
        "model_name = \"bidirectional_lstm\"\n",
        "model = Model.register(model_path=\"outputs/bidirectional_lstm.pkl\",\n",
        "                        model_name=model_name,\n",
        "                        tags={\"area\": \"NLP\", \"model\": \"deep_learning classification\"},\n",
        "                        description=\"Modèle keras bidirectionnal lstm entraîné\",\n",
        "                        workspace=ws)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Créer le script score\n",
        "\n",
        "The script de scoring \"score.py\", est utilisé par lors de l'appel du web service pour utiliser le modèle.\n",
        "\n",
        "Il est composé de 2 fonctions :\n",
        "\n",
        "- **init()** : qui charge le modèle dans un objet globam. Cette fonction est appelée une fois quand le container Docker est démarré.\n",
        "- **run(input_data)** : fonction qui utilise le modèle pour prédire le résultat à partir des données d'entrée."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting score.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile score.py\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import joblib\n",
        "from azureml.core.model import Model\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    model_path = Model.get_model_path(model_name='bidirectional_lstm')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "def run(raw_data):\n",
        "    data = np.array(json.loads(raw_data)['data'])\n",
        "    # make prediction\n",
        "    y_pred_proba = model.predict(data)\n",
        "    # you can return any data type as long as it is JSON-serializable\n",
        "\n",
        "    y_pred = [round(pred_proba[0]) for pred_proba in y_pred_proba.tolist()]\n",
        "\n",
        "    return y_pred_proba.tolist(), y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Fichier de configuration\n",
        "\n",
        "Créer un fichier de configuration de déploiement, spécifier le nombre de CPUs et de RAM à utiliser pour le container."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1655138945232
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 2, memory_gb = 4, auth_enabled=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Création de l'environnement et de l'inférence\n",
        "\n",
        "On spécifie les dépendances nécessaires pour l'environnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1655138947022
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice, Webservice\n",
        "\n",
        "env = Environment('projet_7')\n",
        "\n",
        "cd = CondaDependencies.create(pip_packages=['scikit-learn' ,'keras' ,'tensorflow', 'azureml-defaults'])\n",
        "\n",
        "env.python.conda_dependencies = cd\n",
        "\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
        "                                   environment=env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Déploiement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1655139505903
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2022-06-13 16:49:12+00:00 Creating Container Registry if not exists.\n",
            "2022-06-13 16:49:12+00:00 Registering the environment.\n",
            "2022-06-13 16:49:13+00:00 Use the existing image.\n",
            "2022-06-13 16:49:13+00:00 Generating deployment configuration.\n",
            "2022-06-13 16:49:14+00:00 Submitting deployment to compute.\n",
            "2022-06-13 16:49:20+00:00 Checking the status of deployment tweets-sentiment-analysis..\n",
            "2022-06-13 16:51:28+00:00 Checking the status of inference endpoint tweets-sentiment-analysis.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "source": [
        "service = Model.deploy(workspace=ws, \n",
        "                       name='tweets-sentiment-analysis', \n",
        "                       models=[model], \n",
        "                       inference_config=inference_config, \n",
        "                       deployment_config=deployment_config)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1655139808034
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "m4zJCjMjthcFYsRacsTUBS4RN3xU7lJp\n",
            "http://8b19886d-a159-4585-a9a4-975a4924c7d7.westeurope.azurecontainer.io/score\n"
          ]
        }
      ],
      "source": [
        "primary, secondary = service.get_keys()\n",
        "print(primary)\n",
        "print(service.scoring_uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Test du modèle en appelant le Web Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1655139863182
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[0.9965319037437439], [0.004983492195606232], [0.9657612442970276]], [1, 0, 1]]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "input_payload = json.dumps({\n",
        "    'data': [\"I am having a very good day today\", \"I hate when it's raining outside\", \"My car is very beautiful\"]\n",
        "})\n",
        "output = service.run(input_payload)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Suppression du Web Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1655138780898
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "service.delete()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "projet_7"
    },
    "kernelspec": {
      "display_name": "projet_7",
      "language": "python",
      "name": "projet_7"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
